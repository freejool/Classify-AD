{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "import time\n",
    "import pymongo\n",
    "import json\n",
    "import random\n",
    "import sklearn_relief as relief\n",
    "\n",
    "re=relief.ReliefF()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genericpath import exists\n",
    "import numpy as np\n",
    "from sklearn import svm, tree\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn import pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import sklearn_relief as relief\n",
    "import time\n",
    "import pymongo\n",
    "import random\n",
    "import json\n",
    "import threading\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "\n",
    "rawdata = np.loadtxt(\n",
    "    '/Users/sxing/Developer/matlab/code/sklearn/data.txt', delimiter=',')\n",
    "data = []\n",
    "for row in rawdata:\n",
    "    if row[-1] in [0, 3]:\n",
    "        data.append(row)\n",
    "data = np.array(data)\n",
    "\n",
    "# pipe = pipeline.Pipeline([('pca', PCA(n_components=20)), ('scaler', preprocessing.StandardScaler()), ('sc', preprocessing.Normalizer())])\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(data[:, :-1])\n",
    "data[:, :-1] = scaler.transform(data[:, :-1])\n",
    "normer = preprocessing.Normalizer()\n",
    "normer.fit(data[:, :-1])\n",
    "data[:, :-1] = normer.transform(data[:, :-1])\n",
    "# pca=PCA()\n",
    "# pca.fit(data[:, :-1])\n",
    "# paceddata=pca.transform(data[:, :-1])\n",
    "# data=np.concatenate((paceddata,data[:,-1].reshape(-1,1)),axis=1)\n",
    "r = relief.ReliefF(n_features=50)\n",
    "\n",
    "data = r.fit_transform(data[:, :-1], data[:, -1])\n",
    "\n",
    "\n",
    "\n",
    "x_train = data[:, :-1]\n",
    "y_train = data[:, -1]\n",
    "scores = []\n",
    "score = []\n",
    "\n",
    "for i in range(100):\n",
    "    random.seed(time.time())\n",
    "    kfold = KFold(n_splits=5, shuffle=True,\n",
    "                  random_state=random.randint(0, 100))\n",
    "\n",
    "    for train_index, test_index in kfold.split(x_train, y_train):\n",
    "        # train_index 就是分类的训练集的下标，test_index 就是分配的验证集的下标\n",
    "        # 本组训练集\n",
    "        this_train_x, this_train_y = x_train[train_index], y_train[train_index]\n",
    "        # 本组验证集\n",
    "        this_test_x, this_test_y = x_train[test_index], y_train[test_index]\n",
    "        # 训练本组的数据，并计算准确率\n",
    "\n",
    "        # pipe = pipeline.Pipeline(\n",
    "        #     [('pca', PCA()), ('scaler', preprocessing.StandardScaler()), ('sc', preprocessing.Normalizer()),\n",
    "        #      ('svc', svm.SVC())])\n",
    "        clf = svm.SVC(kernel='linear', C=4)\n",
    "        clf.fit(this_train_x, this_train_y)\n",
    "        score.append(clf.score(this_test_x, this_test_y))\n",
    "    scores.append(np.mean(score))\n",
    "plt.plot(scores)\n",
    "print(np.mean(scores))\n",
    "# print(np.column_stack((clf.predict(test_data_x), test_data_y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = db.get_collection('charpath').find({}).sort('index',pymongo.ASCENDING)\n",
    "\n",
    "ret=np.zeros((102,360))\n",
    "columnidx=0\n",
    "\n",
    "for rowidx,c in enumerate(cursor):\n",
    "    value=c['value']\n",
    "    if type(value)!=list:\n",
    "        value=[value]\n",
    "    ret[rowidx,columnidx:len(value)]=value\n",
    "columnidx+=len(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc=np.ones((100,100))\n",
    "hc = hc[:24, :].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong\n",
      "correct\n",
      "correct\n",
      "correct\n",
      "correct\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(time.localtime()[5])\n",
    "a = np.array([i//25 for i in range(100)])\n",
    "b = rng.random((100, 5))\n",
    "c = np.column_stack((b, a))\n",
    "test=c[:5,:].copy()\n",
    "\n",
    "\n",
    "x=c[:,:-1]\n",
    "y=c[:,-1]\n",
    "clf=svm.SVC()\n",
    "clf.fit(x,y)\n",
    "for i in range(test.shape[0]):\n",
    "    ret=clf.predict([test[i,:-1]])\n",
    "    if ret==test[i,-1]:\n",
    "        print(\"correct\")\n",
    "    else:\n",
    "        print(\"wrong\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "X = [[0, 0], [1, 1]]\n",
    "y = [0, 1]\n",
    "clf = svm.SVC()\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "print(clf.predict([[2., 2.]]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.random.random((100,100))\n",
    "a=data[0:23].copy()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9250710150d997f1ef756a4d4ba6e5a4301dea9dd31a0d90db900d0b0db19f4b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
